{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 02 - Fruit and Vegetable Disease (Healthy vs Rotten) - Kaggle + Vertex AI Training (AutoML) Example\n",
    "\n",
    "* Kaggle page:  https://www.kaggle.com/datasets/muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten\n",
    "* dataset: https://www.kaggle.com/datasets/muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten/data\n",
    "* notebook: https://www.kaggle.com/code/osamaabobakr/fruit-and-vegetable-disease-healthy-vs-rotten\n",
    "\n",
    "by: Justin Marciszewski | justinjm@google.com | AI/ML Specialist CE\n",
    "\n",
    "refs:\n",
    "\n",
    "* https://cloud.google.com/vertex-ai/docs/training-overview\n",
    "* https://cloud.google.com/vertex-ai/docs/tutorials/image-classification-automl/overview\n",
    "* https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_image_classification_online_prediction.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "packages = [\n",
    "    ('numpy', 'numpy'),\n",
    "    ('os', 'os-sys'), # os is built-in, this is for demonstration\n",
    "    ('cv2', 'opencv-python'),\n",
    "    ('re', 're'), # re is built-in, this is for demonstration\n",
    "    ('random', 'random'), # random is built-in, this is for demonstration\n",
    "    ('matplotlib.pyplot', 'matplotlib'),\n",
    "    ('seaborn', 'seaborn'),\n",
    "    ('kaggle.api.kaggle_api_extended', 'kaggle'),\n",
    "    ('sklearn.model_selection', 'scikit-learn'),\n",
    "    ('sklearn.utils', 'scikit-learn'),\n",
    "    ('keras', 'keras'),\n",
    "    ('tensorflow.keras', 'tensorflow'),\n",
    "    ('tensorflow.keras.layers', 'tensorflow'),\n",
    "    ('tensorflow.keras.models', 'tensorflow'),\n",
    "    ('tensorflow.keras.applications', 'tensorflow'),\n",
    "    ('tensorflow.keras.preprocessing.image', 'tensorflow')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    try:\n",
    "        importlib.import_module(package[0])\n",
    "    except ImportError:\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "\n",
    "if install:\n",
    "    print(\"Installation of missing packages complete. Please run the next cell to restart the kernel before proceeding.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Kernel (If Installs Occured)\n",
    "After a kernel restart the code submission can start with the next cell after this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "### Set constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demos-vertex-ai'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"  \n",
    "REGION = 'us-central1' \n",
    "\n",
    "SERIES = \"02-kaggle-vertex-ai\"\n",
    "EXPERIMENT = \"02-automl\" # notebook number \n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fruit-and-veg-image-model\"\n",
    "\n",
    "## model training \n",
    "DESIRED_LABELS = [\n",
    "    'Apple__Healthy', 'Apple__Rotten',\n",
    "    'Banana__Healthy', 'Banana__Rotten',\n",
    "    'Bellpepper__Healthy', 'Bellpepper__Rotten'\n",
    "]\n",
    "NUM_CLASSES = len(DESIRED_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import tempfile\n",
    "import threading\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Data pre-processing\n",
    "from PIL import Image  # For image loading and preprocessing\n",
    "\n",
    "# Modeling \n",
    "from google.cloud import aiplatform\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "URI = f\"gs://{BUCKET_NAME}/{SERIES}/{EXPERIMENT}\" \n",
    "DIR = f\"temp/{EXPERIMENT}\"\n",
    "\n",
    "LOCAL_DATA_DIR = f\"{DIR}/data\"\n",
    "LOCAL_CSV_IMAGE_DATA_PATH = f\"{LOCAL_DATA_DIR}/labels.csv\"\n",
    "\n",
    "DATASET_CSV = f\"{URI}/{TIMESTAMP}/labels.csv\"\n",
    "\n",
    "DATASET_DISPLAY_NAME = f\"{SERIES}-{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FRAMEWORK = 'tf'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'tl'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a local directories for staging files \n",
    "\n",
    "* data files from creating labels.csv\n",
    "* build files for creating custom container and running a custom job \n",
    "* model training output files and example input images for local inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf $LOCAL_DATA_DIR\n",
    "! mkdir -p $LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{DIR}/build\"):\n",
    "    os.makedirs(f\"{DIR}/build\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{DIR}/output\"):\n",
    "    os.makedirs(f\"{DIR}/output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Google Cloud Storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_and_create_bucket(bucket_name, location):\n",
    "    try:\n",
    "        storage_client.get_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except NotFound:\n",
    "        bucket = storage_client.create_bucket(bucket_or_name=bucket_name, location=location)\n",
    "        print(f\"Bucket {bucket_name} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket demos-vertex-ai-fruit-and-veg-image-model created.\n"
     ]
    }
   ],
   "source": [
    "check_and_create_bucket(BUCKET_NAME, LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Kaggle credentials\n",
    "\n",
    "You will need a Kaggle account and locate or create a kaggle.json file in the directory: `/home/jupyter/.config/kaggle`\n",
    "\n",
    "Steps:\n",
    "\n",
    "* manually download your credentail file from kaggle.com -> Profile\n",
    "* run this command in terminal to move it to the correct location: `mv kaggle.json .config/kaggle/kaggle.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten\n"
     ]
    }
   ],
   "source": [
    "# Set up Kaggle credentials \n",
    "os.environ['KAGGLE_USERNAME'] = 'YOUR_KAGGLE_USERNAME' \n",
    "os.environ['KAGGLE_KEY'] = 'YOUR_KAGGLE_API_KEY'\n",
    "\n",
    "# Initialize the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Specify the dataset you want to download\n",
    "dataset_slug = 'muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten'\n",
    "\n",
    "# Download the dataset\n",
    "api.dataset_download_files(dataset_slug, path=LOCAL_DATA_DIR, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_image_to_rgb_and_jpeg(image_path):\n",
    "    \"\"\"Converts and saves an image to RGB JPEG format, overwriting the original.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        img.save(image_path, format='JPEG')  # Overwrite the original\n",
    "        # print(f'Converted and saved: {image_path}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {image_path}: {e}')\n",
    "\n",
    "def process_directory(root_dir, subdirs_to_convert, max_workers=None):\n",
    "    \"\"\"Processes images within specified subdirectories using multithreading.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            # Filter directories based on the provided list\n",
    "            dirs[:] = [d for d in dirs if d in subdirs_to_convert]\n",
    "\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  # Add more extensions if needed\n",
    "                    image_path = Path(root) / file\n",
    "                    executor.submit(convert_image_to_rgb_and_jpeg, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = f\"{LOCAL_DATA_DIR}/Fruit And Vegetable Diseases Dataset\"\n",
    "subdirectories_to_convert = DESIRED_LABELS\n",
    "\n",
    "process_directory(root_directory, subdirectories_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load to GCS\n",
    "\n",
    "Load only a subset of images (set by the `DESIRED_LABELS` list) for demonstration purposes, update the `DESIRED_LABELS` to include all the images in the Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/\n",
      "Successfully copied Apple__Healthy\n",
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Rotten/\n",
      "Successfully copied Apple__Rotten\n",
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Banana__Healthy/\n",
      "Successfully copied Banana__Healthy\n",
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Banana__Rotten/\n",
      "Successfully copied Banana__Rotten\n",
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Bellpepper__Healthy/\n",
      "Successfully copied Bellpepper__Healthy\n",
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Bellpepper__Rotten/\n",
      "Successfully copied Bellpepper__Rotten\n"
     ]
    }
   ],
   "source": [
    "# Loop over each subdirectory (label) and copy the contents using gsutil\n",
    "for subdir in DESIRED_LABELS:\n",
    "    source = f'\"{LOCAL_DATA_DIR}/Fruit And Vegetable Diseases Dataset/{subdir}/*\"'\n",
    "    destination = f\"{URI}/data/{subdir}/\"\n",
    "    print(destination)\n",
    "    command = f\"gsutil -m cp -r {source} {destination} > /dev/null 2>&1\"\n",
    "    \n",
    "    # Execute the command using subprocess\n",
    "    process = subprocess.run(command, shell=True)\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(f\"Successfully copied {subdir}\")\n",
    "    else:\n",
    "        print(f\"Failed to copy {subdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data \n",
    "\n",
    "refs:\n",
    "\n",
    "* https://cloud.google.com/vertex-ai/docs/image-data/classification/prepare-data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv labels file and upload for use in model training\n",
    "\n",
    "Create a csv file called `labels.csv` with the schema:  `gs://filename.jpg, label` \n",
    "\n",
    "This file should contain no headers and be located in GCS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_list(bucket_name):\n",
    "    # get list of all files from bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs()\n",
    "    file_list = ['gs://' + bucket_name + '/' + blob.name for blob in blobs]\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (1).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (10).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (100).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (101).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (102).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (103).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (104).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (105).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (106).jpg',\n",
       " 'gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (107).jpg']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = get_file_list(BUCKET_NAME)\n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(file_list, filter_pattern):\n",
    "    # filter to include on filenames with jpg filename\n",
    "    image_files = [file for file in file_list if file.endswith(('.jpg'))]\n",
    "    df = pd.DataFrame(image_files, columns=['filename'])\n",
    "    \n",
    "    ## filter to only 3 foods per constants set above for demonstration purposes \n",
    "    df = df[df['filename'].str.contains(filter_pattern, regex=True)]\n",
    "    \n",
    "    # Extract the label from the GCS path (it's the second part after the bucket name)\n",
    "    df['label'] = df['filename'].apply(lambda x: x.split('/')[6])  # Assuming the label is in the ith segment of the path\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...</td>\n",
       "      <td>Apple__Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...</td>\n",
       "      <td>Apple__Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...</td>\n",
       "      <td>Apple__Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...</td>\n",
       "      <td>Apple__Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...</td>\n",
       "      <td>Apple__Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              filename  \\\n",
       "0  gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...   \n",
       "1  gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...   \n",
       "2  gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...   \n",
       "3  gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...   \n",
       "4  gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy...   \n",
       "\n",
       "            label  \n",
       "0  Apple__Healthy  \n",
       "1  Apple__Healthy  \n",
       "2  Apple__Healthy  \n",
       "3  Apple__Healthy  \n",
       "4  Apple__Healthy  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 100 # set option to view long strings \n",
    "\n",
    "df_labels = create_dataframe(file_list, \n",
    "                             filter_pattern = '|'.join(DESIRED_LABELS))\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3458"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Banana__Healthy        796\n",
       "Bellpepper__Healthy    603\n",
       "Bellpepper__Rotten     591\n",
       "Apple__Rotten          579\n",
       "Banana__Rotten         570\n",
       "Apple__Healthy         319\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save labels.csv\n",
    "\n",
    "Save labels.csv locally and to GCS Bucket for use in vertex ai training in next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_labels.to_csv(LOCAL_CSV_IMAGE_DATA_PATH, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = storage_client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(f\"{SERIES}/{EXPERIMENT}/{TIMESTAMP}/labels.csv\")\n",
    "blob.upload_from_filename(LOCAL_CSV_IMAGE_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vertex AI Dataset\n",
    "\n",
    "Create a managed Vertex AI dataset. \n",
    "\n",
    "refs:\n",
    "\n",
    "* https://cloud.google.com/vertex-ai/docs/image-data/classification/create-dataset#aiplatform_create_dataset_image_sample-python_vertex_ai_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ImageDataset\n",
      "Create ImageDataset backing LRO: projects/746038361521/locations/us-central1/datasets/7361767459390488576/operations/1075536948531036160\n",
      "ImageDataset created. Resource name: projects/746038361521/locations/us-central1/datasets/7361767459390488576\n",
      "To use this ImageDataset in another session:\n",
      "ds = aiplatform.ImageDataset('projects/746038361521/locations/us-central1/datasets/7361767459390488576')\n",
      "Importing ImageDataset data: projects/746038361521/locations/us-central1/datasets/7361767459390488576\n",
      "Import ImageDataset data backing LRO: projects/746038361521/locations/us-central1/datasets/7361767459390488576/operations/994472155238367232\n",
      "ImageDataset data imported. Resource name: projects/746038361521/locations/us-central1/datasets/7361767459390488576\n"
     ]
    }
   ],
   "source": [
    "dataset = aiplatform.ImageDataset.create(\n",
    "        display_name=f\"{SERIES}_{EXPERIMENT}_{TIMESTAMP}\",\n",
    "        gcs_source=[DATASET_CSV],\n",
    "        import_schema_uri=aiplatform.schema.dataset.ioformat.image.single_label_classification, \n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Submit the AutoML training job to Vertex AI\n",
    "\n",
    "refs\n",
    "\n",
    "* https://cloud.google.com/vertex-ai/docs/image-data/classification/train-model#aiplatform_create_training_pipeline_image_classification_sample-python_vertex_ai_sdk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.AutoMLImageTrainingJob(\n",
    "    display_name=f\"{SERIES}_{EXPERIMENT}_{TIMESTAMP}\",\n",
    "    model_type=\"CLOUD\",\n",
    "    prediction_type=\"classification\",\n",
    "    multi_label=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manual set here if needed \n",
    "# dataset = aiplatform.ImageDataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7325155474532204544?project=746038361521\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "AutoMLImageTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/7325155474532204544 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "model = job.run(\n",
    "    dataset=dataset,\n",
    "    model_display_name=f\"{SERIES}_{EXPERIMENT}_{TIMESTAMP}\",\n",
    "    training_fraction_split=0.4,\n",
    "    validation_fraction_split=0.3,\n",
    "    test_fraction_split=0.3,\n",
    "    budget_milli_node_hours=8000,\n",
    "    disable_early_stopping=False,\n",
    "    sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "\n",
    "refs:\n",
    "\n",
    "* https://cloud.google.com/vertex-ai/docs/image-data/classification/evaluate-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'projects/746038361521/locations/us-central1/models/3254898565356453888@1/evaluations/1553650045042032640', 'metricsSchemaUri': 'gs://google-cloud-aiplatform/schema/modelevaluation/classification_metrics_1.0.0.yaml', 'metrics': {'logLoss': 0.031703793, 'confusionMatrix': {'rows': [[170.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 92.0, 0.0, 0.0, 0.0, 4.0], [1.0, 0.0, 153.0, 5.0, 2.0, 3.0], [0.0, 0.0, 3.0, 175.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0, 238.0, 0.0], [0.0, 0.0, 2.0, 0.0, 1.0, 171.0]], 'annotationSpecs': [{'id': '1047400549055463424', 'displayName': 'Banana__Rotten'}, {'id': '3353243558269157376', 'displayName': 'Apple__Healthy'}, {'id': '3929704310572580864', 'displayName': 'Bellpepper__Rotten'}, {'id': '5659086567482851328', 'displayName': 'Bellpepper__Healthy'}, {'displayName': 'Banana__Healthy', 'id': '6235547319786274816'}, {'displayName': 'Apple__Rotten', 'id': '8541390328999968768'}]}, 'confidenceMetrics': [{'confidenceThreshold': 0.0, 'maxPredictions': 0.0, 'precision': 0.16666667, 'recall': 1.0}, {'maxPredictions': 0.0, 'confidenceThreshold': 0.05, 'recall': 0.9911937, 'precision': 0.9620133}, {'precision': 0.96545106, 'recall': 0.9843444, 'maxPredictions': 0.0, 'confidenceThreshold': 0.1}, {'confidenceThreshold': 0.15, 'recall': 0.98336595, 'precision': 0.9691418, 'maxPredictions': 0.0}, {'recall': 0.9794521, 'confidenceThreshold': 0.2, 'maxPredictions': 0.0, 'precision': 0.9727891}, {'precision': 0.97276264, 'maxPredictions': 0.0, 'confidenceThreshold': 0.25, 'recall': 0.9784736}, {'recall': 0.9784736, 'maxPredictions': 0.0, 'precision': 0.97465885, 'confidenceThreshold': 0.3}, {'confidenceThreshold': 0.35, 'precision': 0.97465885, 'recall': 0.9784736, 'maxPredictions': 0.0}, {'recall': 0.97749513, 'maxPredictions': 0.0, 'precision': 0.97558594, 'confidenceThreshold': 0.4}, {'recall': 0.97749513, 'confidenceThreshold': 0.45, 'maxPredictions': 0.0, 'precision': 0.97749513}, {'confidenceThreshold': 0.5, 'recall': 0.97749513, 'maxPredictions': 0.0, 'precision': 0.97749513}, {'precision': 0.97749513, 'recall': 0.97749513, 'maxPredictions': 0.0, 'confidenceThreshold': 0.55}, {'recall': 0.97553813, 'precision': 0.97745097, 'maxPredictions': 0.0, 'confidenceThreshold': 0.6}, {'precision': 0.97836775, 'recall': 0.9735812, 'maxPredictions': 0.0, 'confidenceThreshold': 0.65}, {'confidenceThreshold': 0.7, 'recall': 0.9735812, 'precision': 0.97836775, 'maxPredictions': 0.0}, {'precision': 0.97834647, 'confidenceThreshold': 0.75, 'maxPredictions': 0.0, 'recall': 0.9726027}, {'maxPredictions': 0.0, 'precision': 0.9802761, 'confidenceThreshold': 0.8, 'recall': 0.9726027}, {'maxPredictions': 0.0, 'recall': 0.96868885, 'confidenceThreshold': 0.85, 'precision': 0.9831182}, {'confidenceThreshold': 0.875, 'recall': 0.9667319, 'precision': 0.98406374, 'maxPredictions': 0.0}, {'precision': 0.984016, 'recall': 0.9637965, 'confidenceThreshold': 0.9, 'maxPredictions': 0.0}, {'confidenceThreshold': 0.91, 'precision': 0.98697394, 'maxPredictions': 0.0, 'recall': 0.9637965}, {'recall': 0.9637965, 'precision': 0.98697394, 'confidenceThreshold': 0.92, 'maxPredictions': 0.0}, {'precision': 0.9889558, 'maxPredictions': 0.0, 'recall': 0.9637965, 'confidenceThreshold': 0.93}, {'precision': 0.9909366, 'confidenceThreshold': 0.94, 'maxPredictions': 0.0, 'recall': 0.962818}, {'recall': 0.962818, 'precision': 0.9919355, 'maxPredictions': 0.0, 'confidenceThreshold': 0.95}, {'confidenceThreshold': 0.96, 'recall': 0.96183956, 'precision': 0.9919273, 'maxPredictions': 0.0}, {'maxPredictions': 0.0, 'precision': 0.991911, 'confidenceThreshold': 0.97, 'recall': 0.95988256}, {'precision': 0.99187815, 'recall': 0.9559687, 'maxPredictions': 0.0, 'confidenceThreshold': 0.98}, {'precision': 0.99387753, 'recall': 0.95303327, 'maxPredictions': 0.0, 'confidenceThreshold': 0.99}, {'precision': 0.9948718, 'confidenceThreshold': 0.995, 'maxPredictions': 0.0, 'recall': 0.9491194}, {'recall': 0.946184, 'confidenceThreshold': 0.996, 'precision': 0.99588054, 'maxPredictions': 0.0}, {'maxPredictions': 0.0, 'recall': 0.94520545, 'confidenceThreshold': 0.997, 'precision': 0.9958763}, {'confidenceThreshold': 0.998, 'precision': 0.9958506, 'maxPredictions': 0.0, 'recall': 0.93933463}, {'maxPredictions': 0.0, 'recall': 0.9315069, 'confidenceThreshold': 0.999, 'precision': 0.9958159}, {'recall': 0.47651663, 'precision': 1.0, 'confidenceThreshold': 1.0, 'maxPredictions': 0.0}], 'auPrc': 0.99769676}, 'createTime': '2024-09-16T21:38:55.848896Z', 'sliceDimensions': ['annotationSpec'], 'annotationSchemaUri': 'gs://google-cloud-aiplatform/schema/dataset/annotation/image_classification_1.0.0.yaml'}\n"
     ]
    }
   ],
   "source": [
    "# # get model resource ID\n",
    "# models = aiplatform.Model.list(filter=f\"display_name={SERIES}_{EXPERIMENT}_{TIMESTAMP}\")\n",
    "\n",
    "model_evaluations = model.list_model_evaluations()\n",
    "\n",
    "for model_evaluation in model_evaluations:\n",
    "    print(model_evaluation.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions \n",
    "\n",
    "https://cloud.google.com/vertex-ai/docs/image-data/classification/get-predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/746038361521/locations/us-central1/endpoints/4047822370843394048/operations/1056818862579777536\n",
      "Endpoint created. Resource name: projects/746038361521/locations/us-central1/endpoints/4047822370843394048\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/746038361521/locations/us-central1/endpoints/4047822370843394048')\n",
      "Deploying model to Endpoint : projects/746038361521/locations/us-central1/endpoints/4047822370843394048\n",
      "Deploy Endpoint model backing LRO: projects/746038361521/locations/us-central1/endpoints/4047822370843394048/operations/1897866092991217664\n",
      "Endpoint model deployed. Resource name: projects/746038361521/locations/us-central1/endpoints/4047822370843394048\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://demos-vertex-ai-fruit-and-veg-image-model/02-kaggle-vertex-ai/02-automl/data/Apple__Healthy/FreshApple (1).jpg Apple__Healthy\n"
     ]
    }
   ],
   "source": [
    "test_item = !gsutil cat $DATASET_CSV | head -n1\n",
    "if len(str(test_item[0]).split(\",\")) == 3:\n",
    "    _, test_item, test_label = str(test_item[0]).split(\",\")\n",
    "else:\n",
    "    test_item, test_label = str(test_item[0]).split(\",\")\n",
    "\n",
    "print(test_item, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(predictions=[{'confidences': [1.08934461e-09, 1.0, 4.14907761e-11, 1.8561274e-11, 3.0299411e-08, 1.9773011e-10], 'ids': ['1047400549055463424', '3353243558269157376', '3929704310572580864', '5659086567482851328', '6235547319786274816', '8541390328999968768'], 'displayNames': ['Banana__Rotten', 'Apple__Healthy', 'Bellpepper__Rotten', 'Bellpepper__Healthy', 'Banana__Healthy', 'Apple__Rotten']}], deployed_model_id='303897317335891968', metadata=None, model_version_id='1', model_resource_name='projects/746038361521/locations/us-central1/models/3254898565356453888', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.io.gfile.GFile(test_item, \"rb\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# The format of each instance should conform to the deployed model's prediction input schema.\n",
    "instances = [{\"content\": base64.b64encode(content).decode(\"utf-8\")}]\n",
    "\n",
    "prediction = endpoint.predict(instances=instances)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup - danger zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undeploy endpoint only \n",
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ! warning - running the code below deletes objects that require \n",
    "## long running processes to recreate\n",
    "\n",
    "# Delete the dataset using the Vertex dataset object\n",
    "## dataset.delete()\n",
    "\n",
    "# Delete the endpoint using the Vertex endpoint object\n",
    "## endpoint.delete()\n",
    "\n",
    "# Delete the model using the Vertex model object\n",
    "##model.delete()\n",
    "\n",
    "# Delete the AutoML trainig job\n",
    "##dag.delete()\n",
    "\n",
    "# Delete Cloud Storage objects that were created\n",
    "## delete_bucket = False  # Set True for deletion\n",
    "## if delete_bucket:\n",
    "##     ! gsutil -m rm -r $BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model for local inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions \n",
    "\n",
    "For downloading model, a sample image and finally making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_blobs_with_prefix(bucket_name, prefix, local_directory):\n",
    "    \n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    for blob in blobs:\n",
    "        # Skip \"directory\" objects\n",
    "        if blob.name.endswith(\"/\"):\n",
    "            continue\n",
    "\n",
    "        # Calculate the relative path within the prefix\n",
    "        relative_path = blob.name[len(prefix):] \n",
    "\n",
    "        # Create the local directory for the relative path\n",
    "        local_file_directory = os.path.join(local_directory, os.path.dirname(relative_path))\n",
    "        os.makedirs(local_file_directory, exist_ok=True)\n",
    "\n",
    "        # Download the blob\n",
    "        local_file_path = os.path.join(local_directory, relative_path)\n",
    "        blob.download_to_filename(local_file_path)\n",
    "        print(f\"Blob {blob.name} downloaded to {local_file_path}.\")\n",
    "\n",
    "        \n",
    "def download_random_jpg(bucket_name, pattern):\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    # Get list of blobs (files) with the pattern\n",
    "    blobs = [blob for blob in bucket.list_blobs() if re.search(pattern, blob.name)]\n",
    "    \n",
    "    if not blobs:\n",
    "        print(\"No files found with the pattern:\", pattern)\n",
    "        return None\n",
    "    \n",
    "    # Choose a random blob\n",
    "    random_blob = random.choice(blobs)\n",
    "\n",
    "    # Download the blob\n",
    "    local_filename = random_blob.name \n",
    "    local_directory = os.path.dirname(local_filename)\n",
    "    os.makedirs(local_directory, exist_ok=True)  # Ensure directory exists\n",
    "    \n",
    "    random_blob.download_to_filename(local_filename)\n",
    "    print(f\"Downloaded {local_filename} from bucket {bucket_name}\")\n",
    "\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    \"\"\"Preprocesses an image for model prediction.\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "    img = img.resize(target_size)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize & set to float32\n",
    "    return img_array  # Remove extra dimension (model handles batching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare an image for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download a random image \n",
    "\n",
    "Filter to only 3 foods for demonstration purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# same set of labels as before\n",
    "downloaded_file = download_random_jpg(\n",
    "    bucket_name=BUCKET_NAME, \n",
    "    pattern=f'({\"|\".join(DESIRED_LABELS)})(?!\\.png$)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## display image to sanity check\n",
    "display(Image.open(downloaded_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## and pre-process image for prediction\n",
    "preprocessed_image = preprocess_image(downloaded_file)\n",
    "# preprocessed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get predicted class \n",
    "\n",
    "And finally download the `label_map.json` to lookup the predicted class name when making prediction so we have a useful output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup downloaded image\n",
    "\n",
    "Delete the downloaded image file to keep local directory clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(downloaded_file):  # Check if the file exists\n",
    "    os.remove(downloaded_file)\n",
    "    print(f\"Deleted downloaded image file: {downloaded_file}\")\n",
    "else:\n",
    "    print(f\"Downloaded image file not found: {downloaded_file}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5045111,
     "sourceId": 8463025,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
