{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest Kaggle data to GCS\n",
    "\n",
    "For staging and use in model training later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"  \n",
    "REGION = 'us-central1' \n",
    "\n",
    "BUCKET_NAME = f\"{PROJECT_ID}-fruit-and-veg-image-model-kaggle-data-staging\"\n",
    "\n",
    "## model training \n",
    "DESIRED_LABELS = [\n",
    "    'Apple__Healthy', 'Apple__Rotten',\n",
    "    'Banana__Healthy', 'Banana__Rotten',\n",
    "    'Bellpepper__Healthy', 'Bellpepper__Rotten'\n",
    "]\n",
    "NUM_CLASSES = len(DESIRED_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Ingestion\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.exceptions import NotFound\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Data pre-processing\n",
    "from PIL import Image  \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "URI = f\"gs://{BUCKET_NAME}\" \n",
    "DIR = f\"temp\"\n",
    "LOCAL_DATA_DIR = f\"{DIR}/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a local directories for staging files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! rm -rf $LOCAL_DATA_DIR\n",
    "! mkdir -p $LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_and_create_bucket(bucket_name, location):\n",
    "    try:\n",
    "        storage_client.get_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except NotFound:\n",
    "        bucket = storage_client.create_bucket(bucket_or_name=bucket_name, location=location)\n",
    "        print(f\"Bucket {bucket_name} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_and_create_bucket(BUCKET_NAME, LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Kaggle credentials\n",
    "\n",
    "You will need a Kaggle account and locate or create a kaggle.json file in the directory: `/home/jupyter/.config/kaggle`\n",
    "\n",
    "Steps:\n",
    "\n",
    "* manually download your credentail file from kaggle.com -> Profile\n",
    "* run this command in terminal to move it to the correct location: `mv kaggle.json .config/kaggle/kaggle.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Kaggle credentials \n",
    "os.environ['KAGGLE_USERNAME'] = 'YOUR_KAGGLE_USERNAME' \n",
    "os.environ['KAGGLE_KEY'] = 'YOUR_KAGGLE_API_KEY'\n",
    "\n",
    "# Initialize the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Specify the dataset you want to download\n",
    "dataset_slug = 'muhammad0subhan/fruit-and-vegetable-disease-healthy-vs-rotten'\n",
    "\n",
    "# Download the dataset\n",
    "api.dataset_download_files(dataset_slug, path=LOCAL_DATA_DIR, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_image_to_rgb_and_jpeg(image_path):\n",
    "    \"\"\"Converts and saves an image to RGB JPEG format, overwriting the original.\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        img.save(image_path, format='JPEG')  # Overwrite the original\n",
    "        # print(f'Converted and saved: {image_path}')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {image_path}: {e}')\n",
    "\n",
    "def process_directory(root_dir, subdirs_to_convert, max_workers=None):\n",
    "    \"\"\"Processes images within specified subdirectories using multithreading.\"\"\"\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            # Filter directories based on the provided list\n",
    "            dirs[:] = [d for d in dirs if d in subdirs_to_convert]\n",
    "\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):  # Add more extensions if needed\n",
    "                    image_path = Path(root) / file\n",
    "                    executor.submit(convert_image_to_rgb_and_jpeg, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_directory = f\"{LOCAL_DATA_DIR}/Fruit And Vegetable Diseases Dataset\"\n",
    "subdirectories_to_convert = DESIRED_LABELS\n",
    "\n",
    "process_directory(root_directory, subdirectories_to_convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load to GCS\n",
    "\n",
    "Load only a subset of images (set by the `DESIRED_LABELS` list) for demonstration purposes, update the `DESIRED_LABELS` to include all the images in the Kaggle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop over each subdirectory (label) and copy the contents using gsutil\n",
    "for subdir in DESIRED_LABELS:\n",
    "    source = f'\"{LOCAL_DATA_DIR}/Fruit And Vegetable Diseases Dataset/{subdir}/*\"'\n",
    "    destination = f\"{URI}/{subdir}/\"\n",
    "    print(destination)\n",
    "    command = f\"gsutil -m cp -r {source} {destination} > /dev/null 2>&1\"\n",
    "    \n",
    "    # Execute the command using subprocess\n",
    "    process = subprocess.run(command, shell=True)\n",
    "    \n",
    "    if process.returncode == 0:\n",
    "        print(f\"Successfully copied {subdir}\")\n",
    "    else:\n",
    "        print(f\"Failed to copy {subdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying to a new bucket\n",
    "\n",
    "For use in model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GCS_DESTINATION = \"YOUR-BUCKET-NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gsutil -m rsync -r gs://$BUCKET_NAME gs://$GCS_DESTINATION/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
